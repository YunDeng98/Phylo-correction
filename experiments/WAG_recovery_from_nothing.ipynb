{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Experiment: Iterating the Pipeline to Recover WAG from nothing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The goal of this experiment is to determine _if_ and _how many_ iteration of our Pipeline are required to recover the WAG matrix (../input_data/synthetic_rate_matrices/WAG_FastTree.txt) from simulated data, starting from the (terrible estimate of the) uniform rate matrix (which can be found at ../input_data/synthetic_rate_matrices/Q1_uniform_FastTree.txt).\n",
    "Each iteration thus consists of:\n",
    "- (Re-)estimating the trees with FastTree, using the current estimate of the rate matrix.\n",
    "- (Re-)estimating the rate matrix.\n",
    "\n",
    "We compare this procedure againt running the pipeline once, using WAG to estimate the trees (i.e. the \"oracle access\" case).\n",
    "\n",
    "Here are the questions that we answer:\n",
    "\n",
    "**QUESTION 1**: Starting from the uniform rate matrix, does the sequence of estimates Q1_1, Q1_2, Q1_3, ... converge to the WAG matrix (../input_data/synthetic_rate_matrices/WAG_FastTree.txt)?\n",
    "\n",
    "**ANSWER**: **No**. In fact, by looking at the sequence of estimates Q1_1, Q1_2, Q1_3, ... we see that they shrink to 0! My explanation is the following: maximum parsimony bias causes us to under-estimate the transition rates. As a consequence, when the trees are re-esimated, their branch lengths are estimated as longer than before. But then the re-estimated rate matrix adapts to the longer branch lengths by having even smaller rates. Induction suggests that the process looks like this: Q1_K = Q1_1 x bias ^ (K-1) where bias < 1 is the maximum parsimony multiplicative bias; similarly tree_K = tree_1 x bias ^ (K-1). This feedback loop makes the estimates shrink to zero. This phenomenon does not depend on the choice of the initial rate matrix used in FastTree: it is an unavoidable consequence of iterating a downward-biased estimator.\n",
    "\n",
    "**QUESTION 2**: Starting from the uniform rate matrix, does the sequence of **normalized** estimates Q1_1_normalized, Q1_2_normalized, Q1_3_normalized, ... converge to the **normalized** WAG matrix (WAG_FastTree_normalized)? (Here Q1_K_normalized is defined as the normalized version of Q1_K, such that the mutation rate under stationarity is 1; similarly for WAG_FastTree_normalized)\n",
    "\n",
    "**ANSWER**: **Pretty much yes!** Indeed, the sequence Q1_1_normalized, Q1_2_normalized, Q1_3_normalized, ... gets quite close to WAG_FastTree_normalized. In fact, to spoil the fun: it seems to converge in 1 step (see the next question).\n",
    "\n",
    "**QUESTION 3**: Starting from the uniform rate matrix, _how fast_ does the sequence of normalized estimates Q1_1_normalized, Q1_2_normalized, Q1_3_normalized, ... converge to the normalized WAG matrix (WAG_FastTree_normalized)?\n",
    "\n",
    "**ANSWER**: **In 1 step**. Indeed, Q1_1_normalized, Q1_2_normalized, Q1_3_normalized, ... are all almost identical, and close to WAG_FastTree_normalized.\n",
    "\n",
    "**QUESTION 4**: Okay, so it looks like our pipeline is able to recover normalized WAG (WAG_FastTree_normalized) after 1 step starting from a garbage estimate. Does this mean that the rate matrix used in FastTree does not matter?\n",
    "\n",
    "**ANSWER**: **Yes**, it looks like the rate matrix used in FastTree barely matters. Using the uniform rate matrix (../input_data/synthetic_rate_matrices/Q1_uniform_FastTree.txt) we obtain the estimate Q1_1_normalized, while using the WAG matrix (../input_data/synthetic_rate_matrices/WAG_FastTree.txt) we obtain the estimate Q1_with_WAG_FastTree_normalized, which are both EXTREMELY similar, and both quite close to the ground truth WAG_FastTree_normalized.\n",
    "\n",
    "**QUESTION 5**: Okay, so the rate matrix used in FastTree does not seem to matter much. Is this because the reconstructed phylogenies are very similar?\n",
    "\n",
    "**ANSWER**: **Yes**. Surprisingly, it seems that reconstructing trees with the uniform rate matrix (../input_data/synthetic_rate_matrices/Q1_uniform_FastTree.txt) or with WAG (../input_data/synthetic_rate_matrices/WAG_FastTree.txt) leads to very similar tree shapes (e.g. see repetition_1/trees/1h75_1_A.newick and using_WAG_FastTree/trees/1h75_1_A.newick respectively). These are, however, clearly different from the ground truth! (which is trees_ground_truth/1h75_1_A.newick)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Global parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_rootdir = \"WAG_recovery_from_nothing\"\n",
    "n_process = 32"
   ]
  },
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Phylo_util\n",
    "\n",
    "if not os.path.exists(experiment_rootdir):\n",
    "    os.makedirs(experiment_rootdir)\n",
    "\n",
    "def init_logger():\n",
    "    logger = logging.getLogger('phylo_correction')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    fmt_str = \"[%(asctime)s] - %(name)s - %(levelname)s - %(message)s\"\n",
    "    formatter = logging.Formatter(fmt_str)\n",
    "\n",
    "    consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "    consoleHandler.setFormatter(formatter)\n",
    "    logger.addHandler(consoleHandler)\n",
    "\n",
    "    fileHandler = logging.FileHandler(\"Phylo-correction.log\")\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "\n",
    "init_logger()"
   ]
  },
  {
   "source": [
    "# First we simulate realistic *ground truth trees*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.phylogeny_generation import PhylogenyGenerator\n",
    "from src.simulation import Simulator\n",
    "from src.pipeline import Pipeline\n",
    "\n",
    "a3m_dir = '../test_input_data/a3m_32_families'\n",
    "pdb_dir = '../test_input_data/pdb_32_families'\n",
    "ground_truth_tree_dir = f'{experiment_rootdir}/trees_ground_truth'\n",
    "\n",
    "def simulate_ground_truth_trees():\n",
    "    ground_truth_phylogeny_generator = PhylogenyGenerator(\n",
    "        a3m_dir=a3m_dir,\n",
    "        n_process=n_process,\n",
    "        expected_number_of_MSAs=32,\n",
    "        outdir=ground_truth_tree_dir,\n",
    "        max_seqs=1024,\n",
    "        max_sites=1024,\n",
    "        rate_matrix='../input_data/synthetic_rate_matrices/WAG_FastTree.txt',\n",
    "        use_cached=True,\n",
    "        max_families=32,\n",
    "    )\n",
    "    ground_truth_phylogeny_generator.run()\n",
    "\n",
    "simulate_ground_truth_trees()"
   ]
  },
  {
   "source": [
    "# Simulate MSAs on the ground truth trees using WAG. (We will try to recover WAG from this data!)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a3m_simulated_dir = f'{experiment_rootdir}/a3m_simulated'\n",
    "contact_simulated_dir = f'{experiment_rootdir}/doesnt_matter'\n",
    "ancestral_states_simulated_dir = f'{experiment_rootdir}/doesnt_matter_either'\n",
    "\n",
    "def simulate_ground_truth_MSAs():\n",
    "    ground_truth_MSA_simulator = Simulator(\n",
    "        a3m_dir=a3m_dir,\n",
    "        tree_dir=ground_truth_tree_dir,\n",
    "        a3m_simulated_dir=a3m_simulated_dir,\n",
    "        contact_simulated_dir=contact_simulated_dir,\n",
    "        ancestral_states_simulated_dir=ancestral_states_simulated_dir,\n",
    "        n_process=n_process,\n",
    "        expected_number_of_MSAs=32,\n",
    "        max_families=32,\n",
    "        simulation_pct_interacting_positions=0.0,  # So that ALL positions evolve under the WAG matrix.\n",
    "        Q1_ground_truth=\"../input_data/synthetic_rate_matrices/WAG_matrix.txt\",\n",
    "        Q2_ground_truth=\"../input_data/synthetic_rate_matrices/Q2_uniform_constrained.txt\",  # Doesn't matter\n",
    "        use_cached=True,\n",
    "    )\n",
    "    ground_truth_MSA_simulator.run()\n",
    "\n",
    "simulate_ground_truth_MSAs()"
   ]
  },
  {
   "source": [
    "# Now, starting from a uniform guess for the transition rate matrix, repeatedly (re-)infer the trees and (re-)infer the rate matrix. Will we converge to WAG? How many iterations will we need? Let's find out!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def to_fast_tree_format(rate_matrix: np.array, output_path: str):\n",
    "        r\"\"\"\n",
    "        Writes out 'rate_matrix' to 'output_path' in FastTree 20 x 21 format, column-stochastic.\n",
    "        \"\"\"\n",
    "        amino_acids = [\"A\", \"R\", \"N\", \"D\", \"C\", \"Q\", \"E\", \"G\", \"H\", \"I\", \"L\", \"K\", \"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]\n",
    "        rate_matrix_df = pd.DataFrame(rate_matrix, index=amino_acids, columns=amino_acids)\n",
    "        pi = Phylo_util.solve_stationery_dist(rate_matrix)\n",
    "        rate_matrix_df = rate_matrix_df.transpose()\n",
    "        rate_matrix_df['*'] = pi\n",
    "        with open(output_path, \"w\") as outfile:\n",
    "            for aa in amino_acids:\n",
    "                outfile.write(aa + \"\\t\")\n",
    "            outfile.write(\"*\\n\")\n",
    "        rate_matrix_df.to_csv(output_path, sep=\"\\t\", header=False, mode='a')\n",
    "\n",
    "def iterate_pipeline_starting_from_uniform_rate_matrix():\n",
    "    rate_matrix_estimates = [\"../input_data/synthetic_rate_matrices/Q1_uniform_FastTree.txt\"]  # We start with the uniform guess.\n",
    "\n",
    "    for repetition in range(1, 6, 1):\n",
    "        pipeline = Pipeline(\n",
    "            outdir=f\"{experiment_rootdir}/repetition_{repetition}\",\n",
    "            max_seqs=1024,\n",
    "            max_sites=1024,\n",
    "            armstrong_cutoff=8.0,\n",
    "            rate_matrix=rate_matrix_estimates[-1],  # We use the last estimate to build the trees!\n",
    "            n_process=32,\n",
    "            expected_number_of_MSAs=32,\n",
    "            max_families=32,\n",
    "            a3m_dir=a3m_simulated_dir,\n",
    "            pdb_dir=pdb_dir,\n",
    "            use_cached=True,\n",
    "            num_epochs=2000,\n",
    "            device='cpu',\n",
    "            center=0.06,\n",
    "            step_size=0.1,\n",
    "            n_steps=50,\n",
    "            keep_outliers=False,\n",
    "            max_height=1000.0,\n",
    "            max_path_height=1000,\n",
    "            precomputed_contact_dir=None,\n",
    "            precomputed_tree_dir=None,\n",
    "            precomputed_maximum_parsimony_dir=None,\n",
    "        )\n",
    "        pipeline.run()\n",
    "        # Write out the learned rate matrix to Q1_K_normalize\n",
    "        learned_rate_matrix = np.loadtxt(\n",
    "            os.path.join(pipeline.learnt_rate_matrix_dir, \"learned_matrix.txt\")\n",
    "        )\n",
    "        learned_rate_matrix_path = f'{experiment_rootdir}/Q1_{repetition}'\n",
    "        to_fast_tree_format(learned_rate_matrix, output_path=learned_rate_matrix_path)\n",
    "        rate_matrix_estimates.append(learned_rate_matrix_path)\n",
    "\n",
    "        # Write out the normalized learned rate matrix: Q1_K_normalized\n",
    "        pi = Phylo_util.solve_stationery_dist(learned_rate_matrix)\n",
    "        mutation_rate = pi @ -np.diag(learned_rate_matrix)\n",
    "        normalized_learned_rate_matrix = learned_rate_matrix / mutation_rate\n",
    "        normalized_learned_rate_matrix_path = f'{experiment_rootdir}/Q1_{repetition}_normalized'\n",
    "        to_fast_tree_format(normalized_learned_rate_matrix, output_path=normalized_learned_rate_matrix_path)\n",
    "\n",
    "iterate_pipeline_starting_from_uniform_rate_matrix()"
   ]
  },
  {
   "source": [
    "# Let's see what we would have gotten in 1 iteration if we had used the WAG matrix to reconstruct the trees (the \"oracle access\" case)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def run_pipeline_using_WAG_for_FastTree():\n",
    "    pipeline = Pipeline(\n",
    "        outdir=f\"{experiment_rootdir}/using_WAG_FastTree\",\n",
    "        max_seqs=1024,\n",
    "        max_sites=1024,\n",
    "        armstrong_cutoff=8.0,\n",
    "        rate_matrix='../input_data/synthetic_rate_matrices/WAG_FastTree.txt',  # We use the ground truth in FastTree!\n",
    "        n_process=32,\n",
    "        expected_number_of_MSAs=32,\n",
    "        max_families=32,\n",
    "        a3m_dir=a3m_simulated_dir,\n",
    "        pdb_dir=pdb_dir,\n",
    "        use_cached=True,\n",
    "        num_epochs=2000,\n",
    "        device='cpu',\n",
    "        center=0.06,\n",
    "        step_size=0.1,\n",
    "        n_steps=50,\n",
    "        keep_outliers=False,\n",
    "        max_height=1000.0,\n",
    "        max_path_height=1000,\n",
    "        precomputed_contact_dir=None,\n",
    "        precomputed_tree_dir=None,\n",
    "        precomputed_maximum_parsimony_dir=None,\n",
    "    )\n",
    "    pipeline.run()\n",
    "    # Write out the learned rate matrix to Q1_with_WAG_FastTree\n",
    "    learned_rate_matrix = np.loadtxt(\n",
    "        os.path.join(pipeline.learnt_rate_matrix_dir, \"learned_matrix.txt\")\n",
    "    )\n",
    "    learned_rate_matrix_path = f'{experiment_rootdir}/Q1_with_WAG_FastTree'\n",
    "    to_fast_tree_format(learned_rate_matrix, output_path=learned_rate_matrix_path)\n",
    "\n",
    "    # Write out the normalized learned rate matrix: Q1_with_WAG_FastTree_normalized\n",
    "    pi = Phylo_util.solve_stationery_dist(learned_rate_matrix)\n",
    "    mutation_rate = pi @ -np.diag(learned_rate_matrix)\n",
    "    normalized_learned_rate_matrix = learned_rate_matrix / mutation_rate\n",
    "    normalized_learned_rate_matrix_path = f'{experiment_rootdir}/Q1_with_WAG_FastTree_normalized'\n",
    "    to_fast_tree_format(normalized_learned_rate_matrix, output_path=normalized_learned_rate_matrix_path)\n",
    "\n",
    "run_pipeline_using_WAG_for_FastTree()"
   ]
  },
  {
   "source": [
    "# Compute normalized WAG matrix (WAG_FastTree_normalized)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalized_WAG_matrix():\n",
    "    WAG_matrix = np.array(pd.read_csv(\"../input_data/synthetic_rate_matrices/WAG_matrix.txt\",sep=\"\\t\").iloc[:20, 1:21])\n",
    "    pi = Phylo_util.solve_stationery_dist(WAG_matrix)\n",
    "    mutation_rate = pi @ -np.diag(WAG_matrix)\n",
    "    normalized_WAG_matrix = WAG_matrix / mutation_rate\n",
    "    normalized_WAG_matrix_path = f'{experiment_rootdir}/WAG_FastTree_normalized'\n",
    "    to_fast_tree_format(normalized_WAG_matrix, output_path=normalized_WAG_matrix_path)\n",
    "\n",
    "compute_normalized_WAG_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}